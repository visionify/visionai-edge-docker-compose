version: '3.8'
# VisionAI Edge Platform - Docker Compose Configuration
# This file contains all services required for the VisionAI Edge deployment
services:
  # ============================================================================
  # MONITORING SERVICES
  # ============================================================================

  # Prometheus - Metrics collection and storage
  visionai-prometheus:
    image: prom/prometheus:latest
    container_name: visionai-prometheus
    restart: unless-stopped
    volumes:
      - prometheus_data:/prometheus
      - ./prometheus:/etc/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=30d'
    ports:
      - '9090:9090'
    networks:
      - visionai-network

  # Grafana - Metrics visualization and dashboards
  visionai-grafana:
    image: grafana/grafana:latest
    container_name: visionai-grafana
    restart: unless-stopped
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SERVER_HTTP_PORT=9091
      - GF_LOG_LEVEL=info
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
      - GF_ANALYTICS_REPORTING_ENABLED=false
      - GF_ANALYTICS_CHECK_FOR_UPDATES=false
      - GF_ANALYTICS_CHECK_FOR_PLUGIN_UPDATES=false
      - GF_ANALYTICS_GOOGLE_ANALYTICS_UA_ID=
      - GF_ANALYTICS_FEEDBACK_LINKS_ENABLED=false
      - GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS=false
      - GF_PLUGINS_ENABLE_ALPHA=false
      - GF_UPDATE_CHECK_ENABLED=false
      - GF_SECURITY_ALLOW_EMBEDDING=false
      - GF_SECURITY_COOKIE_SECURE=true
      - GF_SECURITY_X_XSS_PROTECTION=true
      - GF_SECURITY_X_FRAME_OPTIONS=deny
      - GF_SECURITY_CONTENT_SECURITY_POLICY=true
      - GF_FEATURE_TOGGLES_ENABLE=false
      - GF_TESTDATA_ENABLE=false
    depends_on:
      - visionai-prometheus
    ports:
      - '9091:9091'
    networks:
      - visionai-network

  # ============================================================================
  # AI INFERENCE SERVICES
  # ============================================================================
  
  # NVIDIA Triton Inference Server - Model serving engine
  visionai-triton:
    image: nvcr.io/nvidia/tritonserver:23.10-py3
    container_name: visionai-triton
    restart: unless-stopped
    deploy:
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
    ports:
      - '8000:8000'  # HTTP endpoint
      - '8001:8001'  # gRPC endpoint
      - '8002:8002'  # Metrics endpoint
    volumes:
      - $HOME/.visionai/models-repo:/models
    command: ["tritonserver", "--model-store=/models"]
    networks:
      - visionai-network

  # VisionAI Inference Engine - Main AI processing service
  visionai-inference:
    image: visionify/visionai-inference:hexion
    container_name: visionai-inference
    restart: unless-stopped
    deploy:
      restart_policy:
        condition: always
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
    env_file:
      - ./.env
    ports:
      - '3002:3002'  # API endpoint
      - '3003:3003'  # Metrics check endpoint
    volumes:
      - ${HOME}/.visionai:/App/.visionai
    environment:
      - INSTANCE_ID=1
      - METRICS_PORT=3003
    networks:
      - visionai-network
    depends_on: 
      - visionai-triton

  visionai-inference-2:
    image: visionify/visionai-inference:hexion
    container_name: visionai-inference-2
    restart: unless-stopped
    deploy:
      restart_policy:
        condition: always
      resources:
        reservations:
          devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
    env_file:
      - ./.env
    ports:
      - '3004:3004'  # API endpoint
      - '3005:3005'  # Metrics check endpoint
    volumes:
      - ${HOME}/.visionai:/App/.visionai
    environment:
      - INSTANCE_ID=2
      - METRICS_PORT=3005
    networks:
      - visionai-network
    depends_on: 
      - visionai-triton

# ============================================================================
# NETWORK CONFIGURATION
# ============================================================================
networks:
  visionai-network:
    driver: bridge
    name: visionai-network

# ============================================================================
# VOLUME CONFIGURATION
# ============================================================================
volumes:
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
